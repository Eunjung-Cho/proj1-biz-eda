{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 상품데이터 크롤링"
      ],
      "metadata": {
        "id": "xuNaZDWXcbzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It9-kvfacUJh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "url = 'https://www.ssfshop.com/public/goods/detail/listReview'\n",
        "\n",
        "item_ids = [\n",
        "    \"GM0023102645990\", \"GR2Y24040463208\", \"GM0023102645988\", \"GM0023102645987\", \"GQ3621011525906\",\n",
        "    \"GR2Y24040463238\", \"GM0022081981912\", \"GM0022081981911\", \"GQ3621011525909\", \"GM0024102287131\",\n",
        "    \"GM0024102287130\", \"GR2Y24022710834\", \"GR5L24041844965\", \"GQ3623092161279\", \"GQ3621061670876\",\n",
        "    \"GR2Y24090242142\", \"GR2Y24090242342\", \"GR5L24041842074\", \"GM0023092272987\", \"GM0023092272991\",\n",
        "    \"GM0024082116564\", \"GM0023092272992\", \"GQ3623101885649\", \"GQ3622022185706\", \"GR3L24030545490\",\n",
        "    \"GM0022110300679\", \"GR2Y24030654526\", \"GR1F24022604881\", \"GM0022101479641\", \"GR2Y24090242255\"\n",
        "]\n",
        "\n",
        "review_list = []\n",
        "\n",
        "for item_id in item_ids:\n",
        "    print(f\"Collecting reviews for ITEM_ID: {item_id}\")\n",
        "    page_no = 1\n",
        "    collected_reviews = 0\n",
        "    while collected_reviews < 10:\n",
        "        params = {\n",
        "            'pageNo': page_no,\n",
        "            'sortFlag': '',\n",
        "            'reviewSize': '',\n",
        "            'reviewFlag': '',\n",
        "            'godNo': item_id,\n",
        "            'selectAllYn': 'N',\n",
        "            'reviewColor': '',\n",
        "            'reviewFilterHeight': '',\n",
        "            'reviewFilterWeight': '',\n",
        "            'reviewFilterUsldaySize': '',\n",
        "            'reviewFilterPantsUsldaySize': '',\n",
        "            'godEvlTurn': 0\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        reviews = soup.find_all('li', {'data-godno': item_id})\n",
        "\n",
        "        if not reviews:\n",
        "            break\n",
        "\n",
        "        print(f\"  Collecting page {page_no}\")\n",
        "\n",
        "        for review in reviews:\n",
        "            if collected_reviews >= 10:\n",
        "                break\n",
        "\n",
        "            # Extract rating\n",
        "            stars = review.find('span', class_='rate')\n",
        "            rating = int(re.search(r'point(\\d+)', stars['class'][1]).group(1)) if stars and 'class' in stars.attrs else 'N/A'\n",
        "\n",
        "            # Extract date\n",
        "            date = review.find('span', class_='list-date')\n",
        "            date = date.text.strip() if date else 'N/A'\n",
        "\n",
        "            # Extract user\n",
        "            user = review.find('span', class_='list-id')\n",
        "            user = user.text.strip() if user else 'N/A'\n",
        "\n",
        "            # Extract review text\n",
        "            text = review.find('p', class_='review-txts')\n",
        "            text = text.text.strip() if text else 'N/A'\n",
        "\n",
        "            # Extract image\n",
        "            image = review.find('img')['data-original'] if review.find('img') else 'No Image'\n",
        "\n",
        "            review_list.append({\n",
        "                'ITEM_ID': item_id,\n",
        "                'User': user,\n",
        "                'Date': date,\n",
        "                'Rating': rating,\n",
        "                'Review': text,\n",
        "                'Image': image\n",
        "            })\n",
        "\n",
        "            collected_reviews += 1\n",
        "\n",
        "        page_no += 1\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(review_list)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 리뷰데이터 크롤링"
      ],
      "metadata": {
        "id": "dhMsimsNciSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # 정규식 사용\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 크롬 드라이버 설정\n",
        "service = Service(ChromeDriverManager().install())\n",
        "options = webdriver.ChromeOptions()\n",
        "driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "try:\n",
        "    # 검색 페이지 열기\n",
        "    search_url = \"https://www.ssfshop.com/public/search/search/view?serviceType=SRC&keyword=%EC%9E%A0%EC%98%B7&orderView=SORT_EVL_CNT&pageNo=1&_csrf=98490275-b1f7-4dd9-b4ff-3d807122d66b&tab=GOD&schType=ALL\"\n",
        "    driver.get(search_url)\n",
        "    time.sleep(3)  # 페이지 로딩 대기\n",
        "\n",
        "    # 상위 10개 아이템 링크 수집\n",
        "    item_links = []\n",
        "    items = driver.find_elements(By.CSS_SELECTOR, \"li.god-item > a\")[:10]  # 상위 10개 아이템 선택\n",
        "    for item in items:\n",
        "        link = item.get_attribute(\"href\")\n",
        "        full_link = f\"https://www.ssfshop.com{link}\" if not link.startswith(\"http\") else link  # 절대경로 처리\n",
        "        item_links.append(full_link)\n",
        "\n",
        "    # 리뷰 데이터 저장용 리스트\n",
        "    reviews_data = {\n",
        "        \"상품코드\": [],\n",
        "        \"리뷰일자\": [],\n",
        "        \"평점\": [],\n",
        "        \"리뷰내용\": [],\n",
        "        \"아이템링크\": []  # 아이템 링크 추가\n",
        "    }\n",
        "\n",
        "    # 각 아이템 페이지로 이동하여 리뷰 수집\n",
        "    for link in item_links:\n",
        "        driver.get(link)\n",
        "        time.sleep(3)  # 페이지 로딩 대기\n",
        "\n",
        "        # 최대 리뷰 수\n",
        "        max_reviews = 50\n",
        "        current_count = 0\n",
        "\n",
        "        while current_count < max_reviews:\n",
        "            # 리뷰 리스트 가져오기\n",
        "            review_elements = driver.find_elements(By.CSS_SELECTOR, \"li[data-godno]\")\n",
        "            for review_element in review_elements:\n",
        "                if current_count >= max_reviews:\n",
        "                    break\n",
        "                try:\n",
        "                    # 상품코드\n",
        "                    product_code = review_element.get_attribute(\"data-godno\")\n",
        "\n",
        "                    # 리뷰일자\n",
        "                    try:\n",
        "                        review_date = review_element.find_element(By.CSS_SELECTOR, \"span.list-date\").get_attribute(\"innerText\").strip()\n",
        "                    except:\n",
        "                        review_date = \"N/A\"\n",
        "\n",
        "                    # 평점\n",
        "                    try:\n",
        "                        rate_class = review_element.find_element(By.CSS_SELECTOR, \"span.rate\").get_attribute(\"class\").strip()\n",
        "                        # 정규식을 사용하여 평점 숫자만 추출\n",
        "                        rate = re.search(r'\\d+', rate_class).group() if re.search(r'\\d+', rate_class) else \"N/A\"\n",
        "                    except:\n",
        "                        rate = \"N/A\"\n",
        "\n",
        "                    # 리뷰 내용\n",
        "                    try:\n",
        "                        review_text = review_element.find_element(By.CSS_SELECTOR, \"p.review-txts\").get_attribute(\"innerText\").strip()\n",
        "                    except:\n",
        "                        review_text = \"N/A\"\n",
        "\n",
        "                    # 데이터 저장\n",
        "                    reviews_data[\"상품코드\"].append(product_code)\n",
        "                    reviews_data[\"리뷰일자\"].append(review_date)\n",
        "                    reviews_data[\"평점\"].append(rate)\n",
        "                    reviews_data[\"리뷰내용\"].append(review_text)\n",
        "                    reviews_data[\"아이템링크\"].append(link)  # 현재 아이템 링크 저장\n",
        "\n",
        "                    current_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing review: {e}\")\n",
        "\n",
        "            # 다음 페이지로 이동\n",
        "            try:\n",
        "                next_page = driver.find_element(By.CSS_SELECTOR, \"a.next\")\n",
        "                next_page.click()\n",
        "                time.sleep(3)  # 페이지 로딩 대기\n",
        "            except:\n",
        "                print(\"No more pages to navigate.\")\n",
        "                break\n",
        "\n",
        "    # 데이터프레임 생성\n",
        "    df = pd.DataFrame(reviews_data)\n",
        "\n",
        "    # 저장 경로 설정\n",
        "    output_path = r\"/Users/Jooah_kim/주아리/2025/inner circle/reviews_data22.xlsx\"\n",
        "\n",
        "    # 데이터 저장\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Data saved to {output_path}\")\n",
        "\n",
        "finally:\n",
        "    # 드라이버 종료\n",
        "    driver.quit()"
      ],
      "metadata": {
        "id": "Lx1KOE0WckSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 데이터 분석\n",
        "\n",
        "<aside>\n",
        "💡 텍스트 데이터 분석 프로세스\n",
        "\n",
        "1. 데이터수집\n",
        "    - 소셜 미디어, 리뷰, 뉴스, 대화 데이터 등 다양한 출처에서 텍스트 데이터를 수집.\n",
        "2. 전처리\n",
        "    - 불필요한 단어 제거(불용어 처리), 토큰화, 형태소 분석 등.\n",
        "3. 분석 수행\n",
        "    - 분석 목적에 따라 빈도 분석, 감정 분석, 네트워크 분석 등을 수행.\n",
        "4. 시각화\n",
        "    - 워드 클라우드, 네트워크 그래프, 감정 스코어 분포 등을 통해 결과를 효과적으로 전달.\n",
        "</aside>\n",
        "\n",
        "### 1. 빈도분석\n",
        "\n",
        "- **개념**\n",
        "    - 텍스트 데이터 내 특정 단어, 구문 또는 개체가 등장하는 빈도를 계산하여 주요 키워드 및 패턴을 분석하는 방법입니다.\n",
        "- **활용 예시**\n",
        "    - 고객 리뷰 데이터에서 가장 많이 언급되는 제품의 장점/단점을 파악.\n",
        "    - 뉴스 기사에서 특정 이슈(예: \"기후 변화\", \"AI 기술\")의 언급 빈도를 분석하여 트렌드 확인.\n",
        "- **주요 분석 지표**\n",
        "    - 단어 빈도수 (Word Count)\n",
        "    - TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "### 2. 감정분석\n",
        "\n",
        "- **개념**\n",
        "    - 텍스트 데이터의 정서적 경향(긍정, 부정, 중립)을 파악하는 분석 기법입니다. 주로 자연어 처리(NLP) 기법과 사전 기반 또는 기계 학습 모델을 활용합니다.\n",
        "- **활용 예시**\n",
        "    - 소셜 미디어 게시물에서 브랜드에 대한 고객 감정 분석.\n",
        "    - 영화 리뷰나 상품 리뷰에서 긍정/부정 평가의 비율 계산.\n",
        "- **주요 분석 기법**\n",
        "    - 감정 단어 사전 기반 분석 (e.g., NRC, VADER)\n",
        "    - 딥러닝 모델 기반 감정 분류 (e.g., BERT, GPT 기반 모델)\n",
        "\n",
        "### 3. ⭐️ 네트워크 분석 ⭐️\n",
        "\n",
        "- **개념**\n",
        "    - 텍스트 데이터에서 단어, 문장, 문서 간의 관계를 네트워크 형태로 모델링하여 분석하는 기법입니다.\n",
        "        - 노드(Node): 단어, 구문, 개체 등\n",
        "        - 엣지(Edge): 노드 간 연결 또는 연관성\n",
        "- **분석 유형**\n",
        "    - **연결강도**단어 또는 노드 간의 관계의 강도를 측정. 두 단어가 함께 나타나는 빈도수로 측정하거나, 상관 계수 기반으로 분석.\n",
        "        - **활용 예시**\n",
        "            - 고객 리뷰에서 \"배터리\"와 \"지속시간\"의 높은 연결강도를 확인하여 제품 개선에 활용.\n",
        "            - 뉴스 데이터에서 특정 키워드 간의 연관성을 분석해 트렌드 도출.\n",
        "    - **클러스터링**네트워크에서 서로 밀접히 연결된 노드 그룹을 파악.\n",
        "        - **활용 예시**\n",
        "            - 온라인 커뮤니티의 주제별 논의 클러스터 분류.\n",
        "            - 논문 키워드 네트워크에서 연구 주제 도출\n",
        "\n",
        "### 4. 노드 분석\n",
        "\n",
        "- **개념**\n",
        "    - 네트워크에서 개별 노드의 특성을 분석하여 중요도, 중심성 등을 파악하는 기법입니다.\n",
        "- **주요 분석 지표**\n",
        "    - **중심성(Centrality)**네트워크 내에서 특정 노드의 중요성을 나타냄.\n",
        "        - **Degree Centrality**: 노드와 직접 연결된 엣지의 개수.\n",
        "        - **Betweenness Centrality**: 노드가 다른 노드 간 최단 경로에 포함되는 정도.\n",
        "        - **Closeness Centrality**: 노드가 다른 모든 노드와 얼마나 가까운가를 측정.\n",
        "    - **PageRank**구글 검색 알고리즘의 핵심으로, 연결 구조에서 노드의 중요도를 평가.\n",
        "- **활용 예시**\n",
        "    - 논문 네트워크에서 가장 많이 인용된 논문 파악.\n",
        "    - 소셜 미디어 데이터에서 인플루언서 또는 중심 키워드 도출"
      ],
      "metadata": {
        "id": "hxIfuMW0csQH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFxD1kjBcvs1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}