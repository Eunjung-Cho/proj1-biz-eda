{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "D팀 2주차\n",
        "\n",
        "2주차 진행내용\n",
        "1. 보다 명확한 조사 방향 설정을 위해, 페르소나 수정 및 구체화.\n",
        "2. 상품목록 및 리뷰 데이터 크롤링 코드 보완 및 완성\n",
        "3. 데이터 분석방향 설정\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**1. 페르소나 수정 및 구체화.**\n",
        "\n",
        "\n",
        "- **시장 조사**\n",
        "    - **목표**: 시장에서 어떤 유형의 파자마가 인기 있는지 분석.\n",
        "    - **방법**: 플랫폼 데이터를 크롤링하여 트렌드와 인기 제품 파악.\n",
        "    \n",
        "                    - 패션플랫폼 5개 TOP 30 조사 및 상위 브랜드 집중 분석\n",
        "    \n",
        "    - **결론**: \"00 유형(소재/디자인/색상/가격) 파자마가 시장에서 인기\n",
        "- **구매 의도 분석**\n",
        "    - **목표**: 고객들이 특정 파자마를 구매한 의도와 목적을 파악.\n",
        "    - **방법**: 리뷰 데이터를 통해 구매 동기 및 사용 목적 분석.\n",
        "    - **결론**: 고객들은 대체적으로 \"00”한 목적으로 파자마를 구매\n",
        "- **시장 규모 평가**\n",
        "    - **목표**: 해당 파자마 유형의 시장 규모 추정.\n",
        "    - **방법**: 기타 뉴스, 리포트 분석 및 특정 파자마 플랫폼 판매량 취합\n",
        "    - **결론**: \"00한 파자마\"의 시장 규모는 대략적으로 ~~로 추산.\n",
        "\n",
        "- **브랜드 컨셉 및 판매 목표 설정**\n",
        "    - **목표**: 위의 분석 결과를 기반으로 브랜드 컨셉을 수립하고 판매 전략을 제시.\n",
        "    - **전략**:\n",
        "        - \"00한 컨셉\" 파자마와 런칭 캠페인(구매의도 고려) 제안.\n",
        "        - 시장 규모 분석에 따른 연간/분기별 판매 목표 설정.\n",
        "\n",
        "---\n",
        "\n",
        "- ssf ⇒ 리더님 진행\n",
        "- 지그재그 → 이준님\n",
        "- 29cm → 주아\n",
        "- 에이블리 → 태중님\n",
        "- 퀸잇 → 정태님\n",
        "\n",
        "5개 플랫폼 상위 30개 여부에 따른 브랜드 스코어링 ⇒ **도씨 브랜드 분석 계획**\n",
        "\n",
        "| Rank | Brand              | Total_Score | Appearances | Weighted_Score |\n",
        "|------|--------------------|-------------|-------------|----------------|\n",
        "| 1    | 도씨               | 274         | 3           | 822            |\n",
        "| 2    | 쥬니쥬             | 199         | 1           | 199            |\n",
        "| 3    | 오끼드             | 126         | 1           | 126            |\n",
        "| 4    | 오프아워           | 123         | 1           | 123            |\n",
        "| 5    | 레노마 언더웨어    | 117         | 1           | 117            |\n",
        "| 6    | PALAN             | 103         | 1           | 103            |\n",
        "| 7    | 뎁                 | 96          | 1           | 96             |\n",
        "| 8    | 에이세             | 81          | 1           | 81             |\n",
        "| 9    | 코지마켓           | 69          | 1           | 69             |\n",
        "| 10   | 레노마 언더웨어    | 67          | 1           | 67             |\n",
        "\n",
        "\n",
        "Raw Data\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1E9dqXQ3hNUwIO3emvBv4dXhd3OuIh6GaF3HAlCIxVjA/edit?gid=827244988#gid=827244988\n",
        "\n",
        "\n",
        " .\n",
        "\n",
        "\n",
        "<aside>\n",
        "➡️ Total_Score = Total_Score = Σ(31 - Rank)\n",
        "        각 브랜드가 플랫폼 내에서 획득한 순위 점수의 총합입니다. 높은 순위일수록 점수가 높습니다\n",
        "\n",
        "➡️ Appearances = 해당 브랜드가 등장한 플랫폼의 수\n",
        "\n",
        "➡️ Weighted_Score = Total_Score × Appearances\n",
        "</aside>\n"
      ],
      "metadata": {
        "id": "HlwPB7wyDN8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "2. 상품목록 및 리뷰 데이터 크롤링 코드 보완 및 완성\n",
        "\n",
        "> 아래 코드는 퀸잇 (Seleniu 활용하여서 로컬 파이썬 환경에서만 진행가능)"
      ],
      "metadata": {
        "id": "6nLR685vE4Cd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNCZsHEhCywV"
      },
      "outputs": [],
      "source": [
        "## SELENIUM을 활용한 상품데이터 크롤링 코드\n",
        "#pip install selenium\n",
        "#pip install selenium webdriver-manager\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 크롬 드라이버 자동 설정\n",
        "service = Service(ChromeDriverManager().install())\n",
        "\n",
        "# 크롬 옵션 설정\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--new-window\")  # 새로운 창 열기\n",
        "\n",
        "# 웹드라이버 초기화\n",
        "driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "try:\n",
        "    # 크롬 브라우저로 특정 URL 열기\n",
        "    url = \"https://web.queenit.kr/search?keyword=%ED%8C%8C%EC%9E%90%EB%A7%88\"\n",
        "    driver.get(url)\n",
        "\n",
        "    # 페이지 로딩 대기\n",
        "    time.sleep(3)\n",
        "\n",
        "    # 스크롤 설정\n",
        "    scroll_count = 10  # 스크롤 횟수 설정 (사용자가 변경 가능)\n",
        "    scroll_unit = 5000  # 스크롤 단위\n",
        "\n",
        "    for _ in range(scroll_count):\n",
        "        driver.execute_script(f\"window.scrollBy(0, {scroll_unit});\")\n",
        "        time.sleep(2)  # 스크롤 후 대기 시간\n",
        "\n",
        "    # 데이터 저장용 리스트 초기화\n",
        "    data = {\n",
        "        \"브랜드명\": [],\n",
        "        \"상품명\": [],\n",
        "        \"정가\": [],\n",
        "        \"할인가\": [],\n",
        "        \"할인율\": [],\n",
        "        \"평점\": [],\n",
        "        \"리뷰수\": []\n",
        "    }\n",
        "\n",
        "    # 상품 정보 컨테이너 반복\n",
        "    containers = driver.find_elements(By.CSS_SELECTOR, \"div.css-j7qwjs\")\n",
        "    for container in containers:\n",
        "        products = container.find_elements(By.CSS_SELECTOR, \"a.css-8j52bx\")\n",
        "        for product in products:\n",
        "            try:\n",
        "                # 브랜드명\n",
        "                try:\n",
        "                    brand = product.find_element(By.CSS_SELECTOR, \"div[variant='SpecificProductItemBrand']\").text\n",
        "                except:\n",
        "                    brand = \"\"\n",
        "\n",
        "                # 상품명\n",
        "                try:\n",
        "                    name = product.find_element(By.CSS_SELECTOR, \"div[variant='SpecificProductItemProductName']\").text\n",
        "                except:\n",
        "                    name = \"\"\n",
        "\n",
        "                # 정가\n",
        "                try:\n",
        "                    price_original = product.find_element(By.CSS_SELECTOR, \"div[variant='SubLabelXSmall']\").text\n",
        "                except:\n",
        "                    price_original = \"\"\n",
        "\n",
        "                # 할인가\n",
        "                try:\n",
        "                    price_discounted = product.find_element(By.CSS_SELECTOR, \"div[variant='LabelSmall']\").text\n",
        "                except:\n",
        "                    price_discounted = \"\"\n",
        "\n",
        "                # 할인율\n",
        "                try:\n",
        "                    discount_rate = product.find_element(By.CSS_SELECTOR, \"div[variant='SubLabelSmall']\").text\n",
        "                except:\n",
        "                    discount_rate = \"\"\n",
        "\n",
        "                # 평점 및 리뷰수\n",
        "                try:\n",
        "                    review_elements = product.find_elements(By.CSS_SELECTOR, \"div[variant='SpecificProductItemReview']\")\n",
        "                    if len(review_elements) >= 2:\n",
        "                        rating = review_elements[0].text.split('(')[0].strip()\n",
        "                        reviews = review_elements[1].text.split('(')[-1].replace(\")\", \"\").strip()\n",
        "                    else:\n",
        "                        rating = \"\"\n",
        "                        reviews = \"\"\n",
        "                except:\n",
        "                    rating = \"\"\n",
        "                    reviews = \"\"\n",
        "\n",
        "                # 데이터 추가\n",
        "                data[\"브랜드명\"].append(brand)\n",
        "                data[\"상품명\"].append(name)\n",
        "                data[\"정가\"].append(price_original)\n",
        "                data[\"할인가\"].append(price_discounted)\n",
        "                data[\"할인율\"].append(discount_rate)\n",
        "                data[\"평점\"].append(rating)\n",
        "                data[\"리뷰수\"].append(reviews)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\"Error processing product:\", e)\n",
        "\n",
        "    # 데이터프레임 생성\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(df)\n",
        "\n",
        "    # 데이터프레임을 엑셀 파일로 저장\n",
        "    output_path = r\"D:\\\\python workspace\\\\csv files\\\\product_data.xlsx\"\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Data saved to {output_path}\")\n",
        "\n",
        "finally:\n",
        "    # 드라이버 종료\n",
        "    driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 리뷰데이터 크롤링 코드\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 크롬 드라이버 자동 설정\n",
        "service = Service(ChromeDriverManager().install())\n",
        "\n",
        "# 크롬 옵션 설정\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--new-window\")  # 새로운 창 열기\n",
        "\n",
        "# 웹드라이버 초기화\n",
        "driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "try:\n",
        "    # 크롬 브라우저로 특정 URL 열기\n",
        "    url = \"https://web.queenit.kr/product/ffcc433052f298cabca005da2d5c6bef\"\n",
        "    driver.get(url)\n",
        "\n",
        "    # 페이지 로딩 대기\n",
        "    time.sleep(3)\n",
        "\n",
        "    # 특정 요소가 화면에 나타날 때까지 스크롤\n",
        "    for _ in range(5):  # 최대 5번 스크롤\n",
        "        try:\n",
        "            clickable_element = driver.find_element(By.CSS_SELECTOR, \"a.css-8pj6ef span.MuiTypography-root.MuiTypography-SpecificTabTextDefault.css-1mseikm\")\n",
        "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", clickable_element)\n",
        "            time.sleep(0.5)  # 요소가 위치한 후 대기\n",
        "            actions = ActionChains(driver)\n",
        "            actions.move_to_element(clickable_element).click().perform()\n",
        "            print(\"Element clicked successfully.\")\n",
        "            break\n",
        "        except Exception:\n",
        "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    # 스크롤 설정 (다시 스크롤 반복)\n",
        "    scroll_unit = 5000\n",
        "    for _ in range(10):\n",
        "        driver.execute_script(f\"window.scrollBy(0, {scroll_unit});\")\n",
        "        time.sleep(2)\n",
        "\n",
        "    # 데이터 저장용 리스트 초기화\n",
        "    data = {\n",
        "        \"평점\": [],\n",
        "        \"리뷰작성일\": [],\n",
        "        \"구매옵션\": [],\n",
        "        \"구매평\": [],\n",
        "        \"컬러평\": [],\n",
        "        \"사이즈평\": [],\n",
        "        \"두께평\": []\n",
        "    }\n",
        "\n",
        "    # 리뷰 컨테이너 반복\n",
        "    review_containers = driver.find_elements(By.CSS_SELECTOR, \"div.css-j7qwjs[style*='background-color']\")\n",
        "    for review in review_containers:\n",
        "        try:\n",
        "            # 평점\n",
        "            try:\n",
        "                rating_container = review.find_element(By.CSS_SELECTOR, \"div.review-rating-container.css-u4p24i\")\n",
        "                star_elements = rating_container.find_elements(By.CSS_SELECTOR, \"img[src*='ic_star_full_16']\")\n",
        "                rating = len(star_elements)\n",
        "            except:\n",
        "                rating = \"\"\n",
        "\n",
        "            # 리뷰작성일\n",
        "            try:\n",
        "                review_date = review.find_element(By.CSS_SELECTOR, \"div.MuiBox-root.css-1qqq30y[variant='SubLabelXSmall']\").text\n",
        "            except:\n",
        "                review_date = \"\"\n",
        "\n",
        "            # 구매옵션\n",
        "            try:\n",
        "                purchase_option = review.find_element(By.CSS_SELECTOR, \"div.MuiBox-root.css-1h7f5h8[variant='SubLabelSmall']\").text\n",
        "            except:\n",
        "                purchase_option = \"\"\n",
        "\n",
        "            # 구매평\n",
        "            try:\n",
        "                purchase_review = review.find_element(By.CSS_SELECTOR, \"div.MuiBox-root.css-dcpr20[variant='BodyMedium']\").text\n",
        "            except:\n",
        "                purchase_review = \"\"\n",
        "\n",
        "            # 컬러평, 사이즈평, 두께평\n",
        "            try:\n",
        "                detail_container = review.find_element(By.CSS_SELECTOR, \"div.css-13otrl7\")\n",
        "                color_review = detail_container.find_elements(By.CSS_SELECTOR, \"div.MuiBox-root.css-ho64uk[variant='SubLabelSmall']\")[0].text\n",
        "                size_review = detail_container.find_elements(By.CSS_SELECTOR, \"div.MuiBox-root.css-ho64uk[variant='SubLabelSmall']\")[1].text\n",
        "                thickness_review = detail_container.find_elements(By.CSS_SELECTOR, \"div.MuiBox-root.css-ho64uk[variant='SubLabelSmall']\")[2].text\n",
        "            except:\n",
        "                color_review, size_review, thickness_review = \"\", \"\", \"\"\n",
        "\n",
        "            # 데이터 추가\n",
        "            data[\"평점\"].append(rating)\n",
        "            data[\"리뷰작성일\"].append(review_date)\n",
        "            data[\"구매옵션\"].append(purchase_option)\n",
        "            data[\"구매평\"].append(purchase_review)\n",
        "            data[\"컬러평\"].append(color_review)\n",
        "            data[\"사이즈평\"].append(size_review)\n",
        "            data[\"두께평\"].append(thickness_review)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Error processing review:\", e)\n",
        "\n",
        "    # 데이터프레임 생성\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(df)\n",
        "\n",
        "    # 데이터프레임을 엑셀 파일로 저장\n",
        "    output_path = r\"D:\\\\python workspace\\\\csv files\\\\review_data.xlsx\"\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Data saved to {output_path}\")\n",
        "\n",
        "finally:\n",
        "    # 드라이버 종료\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "XJ8OOIZCFSDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "3. 데이터 분석방향 설정\n",
        "\n",
        "\n",
        "## 텍스트 데이터 분석\n",
        "\n",
        "<aside>\n",
        "💡 텍스트 데이터 분석 프로세스\n",
        "\n",
        "1. 데이터수집\n",
        "    - 소셜 미디어, 리뷰, 뉴스, 대화 데이터 등 다양한 출처에서 텍스트 데이터를 수집.\n",
        "2. 전처리\n",
        "    - 불필요한 단어 제거(불용어 처리), 토큰화, 형태소 분석 등.\n",
        "3. 분석 수행\n",
        "    - 분석 목적에 따라 빈도 분석, 감정 분석, 네트워크 분석 등을 수행.\n",
        "4. 시각화\n",
        "    - 워드 클라우드, 네트워크 그래프, 감정 스코어 분포 등을 통해 결과를 효과적으로 전달.\n",
        "</aside>\n",
        "\n",
        "### 1. 빈도분석\n",
        "\n",
        "- **개념**\n",
        "    - 텍스트 데이터 내 특정 단어, 구문 또는 개체가 등장하는 빈도를 계산하여 주요 키워드 및 패턴을 분석하는 방법입니다.\n",
        "- **활용 예시**\n",
        "    - 고객 리뷰 데이터에서 가장 많이 언급되는 제품의 장점/단점을 파악.\n",
        "    - 뉴스 기사에서 특정 이슈(예: \"기후 변화\", \"AI 기술\")의 언급 빈도를 분석하여 트렌드 확인.\n",
        "- **주요 분석 지표**\n",
        "    - 단어 빈도수 (Word Count)\n",
        "    - TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "### 2. 감정분석\n",
        "\n",
        "- **개념**\n",
        "    - 텍스트 데이터의 정서적 경향(긍정, 부정, 중립)을 파악하는 분석 기법입니다. 주로 자연어 처리(NLP) 기법과 사전 기반 또는 기계 학습 모델을 활용합니다.\n",
        "- **활용 예시**\n",
        "    - 소셜 미디어 게시물에서 브랜드에 대한 고객 감정 분석.\n",
        "    - 영화 리뷰나 상품 리뷰에서 긍정/부정 평가의 비율 계산.\n",
        "- **주요 분석 기법**\n",
        "    - 감정 단어 사전 기반 분석 (e.g., NRC, VADER)\n",
        "    - 딥러닝 모델 기반 감정 분류 (e.g., BERT, GPT 기반 모델)\n",
        "\n",
        "### 3. ⭐️ 네트워크 분석 ⭐️\n",
        "\n",
        "- **개념**\n",
        "    - 텍스트 데이터에서 단어, 문장, 문서 간의 관계를 네트워크 형태로 모델링하여 분석하는 기법입니다.\n",
        "        - 노드(Node): 단어, 구문, 개체 등\n",
        "        - 엣지(Edge): 노드 간 연결 또는 연관성\n",
        "- **분석 유형**\n",
        "    - **연결강도**단어 또는 노드 간의 관계의 강도를 측정. 두 단어가 함께 나타나는 빈도수로 측정하거나, 상관 계수 기반으로 분석.\n",
        "        - **활용 예시**\n",
        "            - 고객 리뷰에서 \"배터리\"와 \"지속시간\"의 높은 연결강도를 확인하여 제품 개선에 활용.\n",
        "            - 뉴스 데이터에서 특정 키워드 간의 연관성을 분석해 트렌드 도출.\n",
        "    - **클러스터링**네트워크에서 서로 밀접히 연결된 노드 그룹을 파악.\n",
        "        - **활용 예시**\n",
        "            - 온라인 커뮤니티의 주제별 논의 클러스터 분류.\n",
        "            - 논문 키워드 네트워크에서 연구 주제 도출\n",
        "\n",
        "### 4. 노드 분석\n",
        "\n",
        "- **개념**\n",
        "    - 네트워크에서 개별 노드의 특성을 분석하여 중요도, 중심성 등을 파악하는 기법입니다.\n",
        "- **주요 분석 지표**\n",
        "    - **중심성(Centrality)**네트워크 내에서 특정 노드의 중요성을 나타냄.\n",
        "        - **Degree Centrality**: 노드와 직접 연결된 엣지의 개수.\n",
        "        - **Betweenness Centrality**: 노드가 다른 노드 간 최단 경로에 포함되는 정도.\n",
        "        - **Closeness Centrality**: 노드가 다른 모든 노드와 얼마나 가까운가를 측정.\n",
        "    - **PageRank**구글 검색 알고리즘의 핵심으로, 연결 구조에서 노드의 중요도를 평가.\n",
        "- **활용 예시**\n",
        "    - 논문 네트워크에서 가장 많이 인용된 논문 파악.\n",
        "    - 소셜 미디어 데이터에서 인플루언서 또는 중심 키워드 도출"
      ],
      "metadata": {
        "id": "eo7NHMkJFOfh"
      }
    }
  ]
}